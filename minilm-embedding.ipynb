{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":909575,"sourceType":"datasetVersion","datasetId":488231}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-17T09:45:57.993969Z","iopub.execute_input":"2025-10-17T09:45:57.994343Z","iopub.status.idle":"2025-10-17T09:46:00.230679Z","shell.execute_reply.started":"2025-10-17T09:45:57.994316Z","shell.execute_reply":"2025-10-17T09:46:00.229745Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/french-twitter-sentiment-analysis/french_tweets.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Importation des biblioth√©ques n√©cessaires","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks, optimizers\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\n\n# Reproductibilit√©\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\ntorch.manual_seed(SEED)\n\n# Style\nsns.set(style='whitegrid')\n\n!pip install -q transformers torch gradio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T09:46:00.231962Z","iopub.execute_input":"2025-10-17T09:46:00.232416Z","iopub.status.idle":"2025-10-17T09:47:43.182849Z","shell.execute_reply.started":"2025-10-17T09:46:00.232390Z","shell.execute_reply":"2025-10-17T09:47:43.181408Z"}},"outputs":[{"name":"stderr","text":"2025-10-17 09:46:08.194402: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760694368.427606      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760694368.493824      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Compr√©hension des donn√©es","metadata":{}},{"cell_type":"code","source":"# Charger les donn√©es\ndata = pd.read_csv('/kaggle/input/french-twitter-sentiment-analysis/french_tweets.csv')\nprint(f\"Taille du dataset : {data.shape}\")\ndata.head()\n\nprint(\"\\nInfo :\")\nprint(data.info())\nprint(\"\\nDistribution originale des labels :\")\nprint(data['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T09:47:43.184157Z","iopub.execute_input":"2025-10-17T09:47:43.185556Z","iopub.status.idle":"2025-10-17T09:47:47.994568Z","shell.execute_reply.started":"2025-10-17T09:47:43.185511Z","shell.execute_reply":"2025-10-17T09:47:47.993734Z"}},"outputs":[{"name":"stdout","text":"Taille du dataset : (1526724, 2)\n\nInfo :\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1526724 entries, 0 to 1526723\nData columns (total 2 columns):\n #   Column  Non-Null Count    Dtype \n---  ------  --------------    ----- \n 0   label   1526724 non-null  int64 \n 1   text    1526724 non-null  object\ndtypes: int64(1), object(1)\nmemory usage: 23.3+ MB\nNone\n\nDistribution originale des labels :\nlabel\n0    771604\n1    755120\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Pr√©paration des donn√©es","metadata":{}},{"cell_type":"markdown","source":"## Nettoyage des textes ","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n    if pd.isna(text):\n        return \"\"\n    text = str(text).lower()\n    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)\n    text = re.sub(r'@\\w+', ' ', text)\n    text = re.sub(r'#', ' ', text)\n    text = re.sub(r'[^a-z0-9√†√¢√§√©√®√™√´√Ø√Æ√¥√∂√π√ª√º√ß≈ì√¶\\-\\s]', ' ', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ndata['text_clean'] = data['text'].astype(str).map(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T09:47:47.996756Z","iopub.execute_input":"2025-10-17T09:47:47.997011Z","iopub.status.idle":"2025-10-17T09:48:07.290277Z","shell.execute_reply.started":"2025-10-17T09:47:47.996990Z","shell.execute_reply":"2025-10-17T09:48:07.289301Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Equilibrage des donn√©es","metadata":{}},{"cell_type":"code","source":"TARGET_PER_CLASS = 60000\n\ndef safe_sample_per_class(df, label_col='label', n=TARGET_PER_CLASS, random_state=SEED):\n    parts = []\n    for lbl, group in df.groupby(label_col):\n        sample_n = min(len(group), n)\n        parts.append(group.sample(n=sample_n, random_state=random_state))\n    return pd.concat(parts).reset_index(drop=True)\n\ndata_balanced = safe_sample_per_class(data, label_col='label', n=TARGET_PER_CLASS)\nprint(\"Distribution √©quilibr√©e :\")\nprint(data_balanced['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T09:48:07.291120Z","iopub.execute_input":"2025-10-17T09:48:07.291420Z","iopub.status.idle":"2025-10-17T09:48:07.665404Z","shell.execute_reply.started":"2025-10-17T09:48:07.291363Z","shell.execute_reply":"2025-10-17T09:48:07.664536Z"}},"outputs":[{"name":"stdout","text":"Distribution √©quilibr√©e :\nlabel\n0    60000\n1    60000\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Chargemenr du mod√©le d'embedding et Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\n\nMODEL_NAME = \"sentence-transformers/all-MiniLM-L12-v2\"\nprint(f\"Chargement du mod√®le MiniLM : {MODEL_NAME}\")\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\nmodel = AutoModel.from_pretrained(MODEL_NAME, trust_remote_code=True)\n\nprint(f\"\\nArchitecture du mod√®le MiniLM :\")\nprint(f\"- Couches: {model.config.num_hidden_layers}\")\nprint(f\"- Dimensions cach√©es: {model.config.hidden_size}\")\nprint(f\"- T√™tes d'attention: {model.config.num_attention_heads}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T09:48:07.666384Z","iopub.execute_input":"2025-10-17T09:48:07.666681Z","iopub.status.idle":"2025-10-17T09:48:25.220535Z","shell.execute_reply.started":"2025-10-17T09:48:07.666660Z","shell.execute_reply":"2025-10-17T09:48:25.219721Z"}},"outputs":[{"name":"stdout","text":"Chargement du mod√®le MiniLM : sentence-transformers/all-MiniLM-L12-v2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/352 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8943b682f2284f98b8e64a6a182b4fbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"895f1266df594e1eb7405fe61c853311"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d42988d6558f4c46afde8a7a8061e756"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c76041ddace46bba7a5a68741b17a08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54ab064cdcee4755961a0927a7ffb0a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4468ee64ccff421c8bcd931b19136115"}},"metadata":{}},{"name":"stdout","text":"\nArchitecture du mod√®le MiniLM :\n- Couches: 12\n- Dimensions cach√©es: 384\n- T√™tes d'attention: 12\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Fonction de pooling + embeddings","metadata":{}},{"cell_type":"code","source":"def mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output.last_hidden_state\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n    return sum_embeddings / sum_mask\n\ndef get_minilm_embeddings(texts, batch_size=32):\n    model.eval()\n    all_embeddings = []\n    for i in range(0, len(texts), batch_size):\n        batch_texts = texts[i:i+batch_size]\n        encoded_input = tokenizer(\n            batch_texts.tolist(),\n            padding=True,\n            truncation=True,\n            max_length=128,\n            return_tensors='pt'\n        )\n        with torch.no_grad():\n            model_output = model(**encoded_input)\n        embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n        all_embeddings.extend(embeddings.numpy())\n    return np.array(all_embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T09:48:25.221300Z","iopub.execute_input":"2025-10-17T09:48:25.221540Z","iopub.status.idle":"2025-10-17T09:48:25.228297Z","shell.execute_reply.started":"2025-10-17T09:48:25.221521Z","shell.execute_reply":"2025-10-17T09:48:25.227364Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Application des embeddings","metadata":{}},{"cell_type":"code","source":"texts = data_balanced['text_clean']\nlabels = data_balanced['label']\n\nminilm_embeddings = get_minilm_embeddings(texts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T09:54:38.423911Z","iopub.execute_input":"2025-10-17T09:54:38.424970Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_texts = pd.Series([\n    \"J'adore ce produit !\",\n    \"Je d√©teste ce service.\",\n    \"C'√©tait correct, sans plus.\"\n])\n\nemb_test = get_minilm_embeddings(test_texts)\nprint(\"Shape des embeddings :\", emb_test.shape)\nprint(emb_test[0][:10])  # premi√®res valeurs pour v√©rifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T09:48:25.252986Z","iopub.execute_input":"2025-10-17T09:48:25.253884Z","iopub.status.idle":"2025-10-17T09:48:25.375608Z","shell.execute_reply.started":"2025-10-17T09:48:25.253850Z","shell.execute_reply":"2025-10-17T09:48:25.374847Z"}},"outputs":[{"name":"stdout","text":"Shape des embeddings : (3, 384)\n[-0.22523013  0.5134914   0.187118   -0.3391628  -0.11511293 -0.0803717\n  0.26003262  0.203393   -0.22086304 -0.02835667]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Visualisation PCA et t-SNE","metadata":{}},{"cell_type":"code","source":"# PCA\npca = PCA()\npca.fit(minilm_embeddings)\nplt.figure(figsize=(10,5))\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('Nombre de composantes PCA')\nplt.ylabel('Variance expliqu√©e cumul√©e')\nplt.title('PCA sur les embeddings MiniLM')\nplt.grid(True)\nplt.show()\n\n# t-SNE\nle = LabelEncoder()\nlabels_encoded = le.fit_transform(labels)\ntsne = TSNE(n_components=2, random_state=SEED, perplexity=30)\nembeddings_2d = tsne.fit_transform(minilm_embeddings)\n\nplt.figure(figsize=(12,8))\nplt.scatter(embeddings_2d[:,0], embeddings_2d[:,1], c=labels_encoded, cmap='Set2', s=8, alpha=0.7)\nplt.title(\"t-SNE - MiniLM embeddings\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T09:48:25.377665Z","iopub.execute_input":"2025-10-17T09:48:25.377904Z","iopub.status.idle":"2025-10-17T09:48:25.414539Z","shell.execute_reply.started":"2025-10-17T09:48:25.377885Z","shell.execute_reply":"2025-10-17T09:48:25.413493Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/459788080.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# PCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminilm_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'minilm_embeddings' is not defined"],"ename":"NameError","evalue":"name 'minilm_embeddings' is not defined","output_type":"error"}],"execution_count":10},{"cell_type":"markdown","source":"# Mod√©lisation","metadata":{}},{"cell_type":"markdown","source":"## Entra√Ænement du classificateur","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    minilm_embeddings, labels, test_size=0.2, random_state=SEED, stratify=labels\n)\n\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nnum_classes = len(label_encoder.classes_)\ninput_dim = X_train.shape[1]\n\nprint(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\nprint(f\"Nombre de classes : {num_classes}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T09:48:25.415271Z","iopub.status.idle":"2025-10-17T09:48:25.415529Z","shell.execute_reply.started":"2025-10-17T09:48:25.415406Z","shell.execute_reply":"2025-10-17T09:48:25.415418Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## R√©seau de neurones","metadata":{}},{"cell_type":"code","source":"def build_minilm_classifier(input_dim, num_classes):\n    model = models.Sequential([\n        layers.Dense(256, activation='relu', input_shape=(input_dim,)),\n        layers.BatchNormalization(),\n        layers.Dropout(0.4),\n\n        layers.Dense(128, activation='relu'),\n        layers.BatchNormalization(),\n        layers.Dropout(0.3),\n\n        layers.Dense(64, activation='relu'),\n        layers.Dropout(0.2),\n\n        layers.Dense(num_classes, activation='softmax')\n    ])\n\n    model.compile(\n        optimizer=optimizers.Adam(0.001),\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model\n\nclassifier = build_minilm_classifier(input_dim, num_classes)\nclassifier.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T09:48:25.416558Z","iopub.status.idle":"2025-10-17T09:48:25.416916Z","shell.execute_reply.started":"2025-10-17T09:48:25.416734Z","shell.execute_reply":"2025-10-17T09:48:25.416751Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Entra√Ænement","metadata":{}},{"cell_type":"code","source":"early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\nhistory = classifier.fit(\n    X_train, y_train_encoded,\n    validation_data=(X_test, y_test_encoded),\n    epochs=10,\n    batch_size=256,\n    callbacks=[early_stop],\n    verbose=1\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"y_pred = classifier.predict(X_test)\ny_pred_labels = np.argmax(y_pred, axis=1)\n\nprint(\"Rapport de classification :\")\nprint(classification_report(y_test_encoded, y_pred_labels, target_names=label_encoder.classes_))\n\ncm = confusion_matrix(y_test_encoded, y_pred_labels)\nplt.figure(figsize=(8,6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\nplt.title('Matrice de confusion')\nplt.ylabel('Vrai label')\nplt.xlabel('Label pr√©dit')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# D√©ploiement","metadata":{}},{"cell_type":"code","source":"import gradio as gr\nimport pandas as pd\n\n# ‚ö†Ô∏è Ici, on suppose que `clean_text`, `tokenizer`, `model_minilm` et `classifier`\n# sont d√©j√† d√©finis et entra√Æn√©s dans les cellules pr√©c√©dentes.\n\n# üß† Fonction pour pr√©dire le sentiment d‚Äôun texte unique\ndef predict_sentiment(text):\n    if not text.strip():\n        return \"‚ö†Ô∏è Texte vide\"\n    cleaned_text = clean_text(text)\n    emb = get_minilm_embeddings(pd.Series([cleaned_text]))\n    prediction = classifier.predict(emb)\n    label_id = prediction.argmax(axis=1)[0]\n    label = label_encoder.inverse_transform([label_id])[0]\n    return label\n\n# üìÇ Fonction pour pr√©dire le sentiment d‚Äôun fichier texte (ou CSV)\ndef predict_file(file):\n    if file is None:\n        return \"Aucun fichier upload√©\"\n\n    # Lecture du fichier\n    try:\n        df = pd.read_csv(file.name, header=None, names=['text'])\n    except Exception:\n        with open(file.name, 'r', encoding='utf-8') as f:\n            lines = f.readlines()\n        df = pd.DataFrame(lines, columns=['text'])\n\n    df['text_clean'] = df['text'].map(clean_text)\n    embeddings = get_minilm_embeddings(df['text_clean'])\n    preds = classifier.predict(embeddings)\n    label_ids = preds.argmax(axis=1)\n    df['sentiment'] = label_encoder.inverse_transform(label_ids)\n\n    return df[['text', 'sentiment']]\n\n# üé® Interface Gradio\nwith gr.Blocks() as demo:\n    gr.Markdown(\"## üß† Analyse de Sentiment des Tweets en Fran√ßais\")\n    gr.Markdown(\"Pr√©disez si un tweet ou un fichier contient des sentiments **positifs** ou **n√©gatifs**.\")\n\n    with gr.Tab(\"üìå Pr√©diction par texte\"):\n        text_input = gr.Textbox(label=\"Entrez un texte ou un tweet\", placeholder=\"Ex: J'adore ce produit !\")\n        output_label = gr.Label(label=\"Sentiment\")\n        btn1 = gr.Button(\"Pr√©dire\")\n        btn1.click(fn=predict_sentiment, inputs=text_input, outputs=output_label)\n\n    with gr.Tab(\"üìÇ Pr√©diction par fichier\"):\n        file_input = gr.File(label=\"Uploader un fichier TXT ou CSV\")\n        output_dataframe = gr.Dataframe(headers=[\"Texte\", \"Sentiment\"])\n        btn2 = gr.Button(\"Analyser le fichier\")\n        btn2.click(fn=predict_file, inputs=file_input, outputs=output_dataframe)\n\ndemo.launch()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}